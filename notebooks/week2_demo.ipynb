{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# Week 2: Generation with MC Dropout Uncertainty\n",
    "\n",
    "This notebook demos the generation pipeline built in Week 2:\n",
    "- **MCDropoutModel** — wraps distilgpt2 with stochastic forward passes\n",
    "- **UncertaintyEstimator** — predictive entropy, mutual information, diversity\n",
    "- **UncertainGenerator** — ties it all together with retrieval results\n",
    "\n",
    "We'll walk through each piece, then run the full pipeline end-to-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2c3d4e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T22:21:18.315793Z",
     "iopub.status.busy": "2026-02-13T22:21:18.315714Z",
     "iopub.status.idle": "2026-02-13T22:21:22.061068Z",
     "shell.execute_reply": "2026-02-13T22:21:22.060539Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from src.generation import MCDropoutModel, UncertaintyEstimator, UncertainGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4e5f6",
   "metadata": {},
   "source": [
    "## 1. MC Dropout Model\n",
    "\n",
    "Load distilgpt2 and verify dropout layers exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4e5f6a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T22:21:22.062456Z",
     "iopub.status.busy": "2026-02-13T22:21:22.062328Z",
     "iopub.status.idle": "2026-02-13T22:21:22.857957Z",
     "shell.execute_reply": "2026-02-13T22:21:22.857546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ce64bffe664cb99e3ddb30adaec30b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mGPT2LMHeadModel LOAD REPORT\u001b[0m from: distilgpt2\n",
      "Key                                        | Status     |  | \n",
      "-------------------------------------------+------------+--+-\n",
      "transformer.h.{0, 1, 2, 3, 4, 5}.attn.bias | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 dropout layers in distilgpt2\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "model = MCDropoutModel(model_name='distilgpt2')\n",
    "\n",
    "import torch.nn as nn\n",
    "dropout_layers = [m for m in model.model.modules() if isinstance(m, nn.Dropout)]\n",
    "print(f'Found {len(dropout_layers)} dropout layers in distilgpt2')\n",
    "print(f'Device: {model.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6a7b8",
   "metadata": {},
   "source": [
    "### Dropout toggle demo\n",
    "\n",
    "Show that enabling dropout puts only those layers in train mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6a7b8c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T22:21:22.859302Z",
     "iopub.status.busy": "2026-02-13T22:21:22.859237Z",
     "iopub.status.idle": "2026-02-13T22:21:22.862087Z",
     "shell.execute_reply": "2026-02-13T22:21:22.861641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout training=True, p=0.1\n",
      "\n",
      "After disable:\n",
      "Dropout training=False\n"
     ]
    }
   ],
   "source": [
    "model._enable_dropout()\n",
    "for m in model.model.modules():\n",
    "    if isinstance(m, nn.Dropout):\n",
    "        print(f'Dropout training={m.training}, p={m.p}')\n",
    "        break\n",
    "\n",
    "model._disable_dropout()\n",
    "print('\\nAfter disable:')\n",
    "for m in model.model.modules():\n",
    "    if isinstance(m, nn.Dropout):\n",
    "        print(f'Dropout training={m.training}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8c9d0",
   "metadata": {},
   "source": [
    "### Generate multiple samples\n",
    "\n",
    "With dropout on, each forward pass uses a different mask — so we get diverse outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8c9d0e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T22:21:22.863123Z",
     "iopub.status.busy": "2026-02-13T22:21:22.863063Z",
     "iopub.status.idle": "2026-02-13T22:21:25.524217Z",
     "shell.execute_reply": "2026-02-13T22:21:25.523640Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \"The capital of France is\"\n",
      "\n",
      "Sample 1:  the nation of the European Empire. The region of the European countries of the ...\n",
      "Sample 2:  a city where the public's bodies and the public live. But the public's rights c...\n",
      "Sample 3:  in the midst of the current economic crisis. This year's economic and social pr...\n",
      "Sample 4:  in French and British eyes. If you are lucky it could be the largest private ai...\n",
      "Sample 5:  the second highest ever capital in France. In April, 2012, there were 18,000 fo...\n"
     ]
    }
   ],
   "source": [
    "prompt = \"The capital of France is\"\n",
    "result = model.generate(prompt, n_samples=5, max_new_tokens=30)\n",
    "\n",
    "print(f'Prompt: \"{prompt}\"\\n')\n",
    "for i, txt in enumerate(result['texts']):\n",
    "    print(f'Sample {i+1}: {txt[:80]}...' if len(txt) > 80 else f'Sample {i+1}: {txt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0e1f2",
   "metadata": {},
   "source": [
    "### Forward pass logits\n",
    "\n",
    "Get raw logits for uncertainty computation. Shape: `(n_samples, seq_len, vocab_size)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0e1f2a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T22:21:25.528237Z",
     "iopub.status.busy": "2026-02-13T22:21:25.528090Z",
     "iopub.status.idle": "2026-02-13T22:21:25.703653Z",
     "shell.execute_reply": "2026-02-13T22:21:25.703192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([10, 5, 50257])\n",
      "  -> 10 MC samples, 5 tokens, 50257 vocab size\n"
     ]
    }
   ],
   "source": [
    "input_ids = model.tokenizer(prompt, return_tensors='pt')['input_ids']\n",
    "logits = model.forward_pass(input_ids, n_samples=10)\n",
    "print(f'Logits shape: {logits.shape}')\n",
    "print(f'  -> {logits.shape[0]} MC samples, {logits.shape[1]} tokens, {logits.shape[2]} vocab size')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2a3b4",
   "metadata": {},
   "source": [
    "## 2. Uncertainty Estimation\n",
    "\n",
    "The core math: predictive entropy (total), expected entropy (aleatoric), and mutual information (epistemic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a3b4c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T22:21:25.705393Z",
     "iopub.status.busy": "2026-02-13T22:21:25.705316Z",
     "iopub.status.idle": "2026-02-13T22:21:25.739734Z",
     "shell.execute_reply": "2026-02-13T22:21:25.739303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-token uncertainty metrics:\n",
      "  Predictive entropy (total):    [7.857 3.138 5.887 3.238 5.489]\n",
      "  Expected entropy (aleatoric):  [7.781 3.015 5.772 3.    5.389]\n",
      "  Mutual information (epistemic): [0.075 0.123 0.116 0.238 0.1  ]\n",
      "\n",
      "Sequence-level:\n",
      "  Mean entropy: 5.1218\n",
      "  Mean MI:      0.1303\n"
     ]
    }
   ],
   "source": [
    "estimator = UncertaintyEstimator()\n",
    "\n",
    "h_pred = estimator.predictive_entropy(logits)\n",
    "h_exp = estimator.expected_entropy(logits)\n",
    "mi = estimator.mutual_information(logits)\n",
    "\n",
    "print('Per-token uncertainty metrics:')\n",
    "print(f'  Predictive entropy (total):    {h_pred.numpy().round(3)}')\n",
    "print(f'  Expected entropy (aleatoric):  {h_exp.numpy().round(3)}')\n",
    "print(f'  Mutual information (epistemic): {mi.numpy().round(3)}')\n",
    "print(f'\\nSequence-level:')\n",
    "print(f'  Mean entropy: {estimator.sequence_entropy(logits):.4f}')\n",
    "print(f'  Mean MI:      {estimator.sequence_mi(logits):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4c5d6",
   "metadata": {},
   "source": [
    "### Sanity check: MI should always be between 0 and H_predictive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4c5d6e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T22:21:25.741251Z",
     "iopub.status.busy": "2026-02-13T22:21:25.741180Z",
     "iopub.status.idle": "2026-02-13T22:21:25.744320Z",
     "shell.execute_reply": "2026-02-13T22:21:25.743948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checks passed: 0 <= MI <= H_predictive for all tokens\n"
     ]
    }
   ],
   "source": [
    "assert (mi >= 0).all(), 'MI should be non-negative'\n",
    "assert (mi <= h_pred + 1e-5).all(), 'MI should be <= predictive entropy'\n",
    "print('Checks passed: 0 <= MI <= H_predictive for all tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d6e7f8",
   "metadata": {},
   "source": [
    "### Text diversity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6e7f8a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T22:21:25.745492Z",
     "iopub.status.busy": "2026-02-13T22:21:25.745435Z",
     "iopub.status.idle": "2026-02-13T22:21:25.747544Z",
     "shell.execute_reply": "2026-02-13T22:21:25.747183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique ratio: 1.00\n",
      "Pairwise diversity: 0.932\n"
     ]
    }
   ],
   "source": [
    "samples = result['texts']\n",
    "print(f'Unique ratio: {estimator.unique_ratio(samples):.2f}')\n",
    "print(f'Pairwise diversity: {estimator.pairwise_diversity(samples):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f8a9b0",
   "metadata": {},
   "source": [
    "### Compare: high vs low uncertainty inputs\n",
    "\n",
    "Uniform logits (max uncertainty) vs peaked logits (min uncertainty)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8a9b0c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T22:21:25.748917Z",
     "iopub.status.busy": "2026-02-13T22:21:25.748867Z",
     "iopub.status.idle": "2026-02-13T22:21:25.752552Z",
     "shell.execute_reply": "2026-02-13T22:21:25.752297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform logits entropy:  3.9120  (max possible: 3.9120)\n",
      "Peaked logits entropy:   0.000000  (near zero)\n"
     ]
    }
   ],
   "source": [
    "vocab = 50\n",
    "\n",
    "# uniform -> high entropy\n",
    "uniform_logits = torch.zeros(5, 3, vocab)\n",
    "h_uniform = estimator.sequence_entropy(uniform_logits)\n",
    "\n",
    "# peaked -> low entropy\n",
    "peaked_logits = torch.full((5, 3, vocab), -100.0)\n",
    "peaked_logits[:, :, 0] = 100.0\n",
    "h_peaked = estimator.sequence_entropy(peaked_logits)\n",
    "\n",
    "print(f'Uniform logits entropy:  {h_uniform:.4f}  (max possible: {np.log(vocab):.4f})')\n",
    "print(f'Peaked logits entropy:   {h_peaked:.6f}  (near zero)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b0c1d2",
   "metadata": {},
   "source": [
    "## 3. Full Pipeline: UncertainGenerator\n",
    "\n",
    "Simulate retrieval docs (as if coming from Week 1's BayesianRetriever) and run the full generation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0c1d2e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T22:21:25.753614Z",
     "iopub.status.busy": "2026-02-13T22:21:25.753562Z",
     "iopub.status.idle": "2026-02-13T22:21:25.755789Z",
     "shell.execute_reply": "2026-02-13T22:21:25.755447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated retrieval docs:\n",
      "  [1] posterior_mean=0.72, std=0.11, entropy=0.45\n",
      "  [2] posterior_mean=0.65, std=0.09, entropy=0.38\n"
     ]
    }
   ],
   "source": [
    "# fake retrieval results with posterior uncertainty from Week 1\n",
    "fake_docs = [\n",
    "    {\n",
    "        'document': 'The Eiffel Tower is a wrought-iron lattice tower in Paris, France. '\n",
    "                    'It was constructed from 1887 to 1889 as the centerpiece of the 1889 World\\'s Fair.',\n",
    "        'posterior_mean': 0.72,\n",
    "        'posterior_std': 0.11,\n",
    "        'entropy': 0.45,\n",
    "        'ci_lower': 0.52,\n",
    "        'ci_upper': 0.88,\n",
    "    },\n",
    "    {\n",
    "        'document': 'Paris has a population of approximately 2.1 million residents. '\n",
    "                    'The city is a major European center for finance, diplomacy, and the arts.',\n",
    "        'posterior_mean': 0.65,\n",
    "        'posterior_std': 0.09,\n",
    "        'entropy': 0.38,\n",
    "        'ci_lower': 0.48,\n",
    "        'ci_upper': 0.81,\n",
    "    },\n",
    "]\n",
    "\n",
    "print('Simulated retrieval docs:')\n",
    "for i, d in enumerate(fake_docs):\n",
    "    print(f'  [{i+1}] posterior_mean={d[\"posterior_mean\"]}, std={d[\"posterior_std\"]}, entropy={d[\"entropy\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1d2e3f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T22:21:25.756958Z",
     "iopub.status.busy": "2026-02-13T22:21:25.756775Z",
     "iopub.status.idle": "2026-02-13T22:21:28.997895Z",
     "shell.execute_reply": "2026-02-13T22:21:28.997380Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Generated Prompt ===\n",
      "Context:\n",
      "[1] The Eiffel Tower is a wrought-iron lattice tower in Paris, France. It was constructed from 1887 to 1889 as the centerpiece of the 1889 World's Fair.\n",
      "[2] Paris has a population of approximately 2.1 million residents. The city is a major European center for finance, diplomacy, and the arts.\n",
      "\n",
      "Question: Where is the Eiffel Tower located?\n",
      "Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generator = UncertainGenerator(\n",
    "    mc_model=model,\n",
    "    estimator=estimator,\n",
    "    default_samples=5,\n",
    "    max_new_tokens=40,\n",
    ")\n",
    "\n",
    "result = generator.generate('Where is the Eiffel Tower located?', fake_docs)\n",
    "\n",
    "print('=== Generated Prompt ===')\n",
    "print(result['prompt'])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2e3f4a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T22:21:28.999405Z",
     "iopub.status.busy": "2026-02-13T22:21:28.999313Z",
     "iopub.status.idle": "2026-02-13T22:21:29.001409Z",
     "shell.execute_reply": "2026-02-13T22:21:29.000994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MC Dropout Samples ===\n",
      "  [1]  What is the Eiffel Tower?\n",
      "Question: The Eiffel Tower was originally built in 1890, and was construc...\n",
      "  [2]  According to estimates of U.S. visitors in each of the six cities with the Eiffel Tower, up to 200 ...\n",
      "  [3]  There is a building called the Eiffel Tower in Paris on a five-story structure and an underground t...\n",
      "  [4]  It is a building of the world's biggest trade center.\n",
      "Question: Why are these towers located inside...\n",
      "  [5]  The Eiffel Tower is a substantial structure, constructed from 1904, in the city and used in the con...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('=== MC Dropout Samples ===')\n",
    "for i, s in enumerate(result['samples']):\n",
    "    print(f'  [{i+1}] {s[:100]}' + ('...' if len(s) > 100 else ''))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3f4a5b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T22:21:29.002561Z",
     "iopub.status.busy": "2026-02-13T22:21:29.002487Z",
     "iopub.status.idle": "2026-02-13T22:21:29.004594Z",
     "shell.execute_reply": "2026-02-13T22:21:29.004299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Generation Uncertainty ===\n",
      "  Sequence entropy:    3.4752\n",
      "  Mean MI (epistemic): 0.0439\n",
      "  Unique ratio:        1.00\n",
      "  Pairwise diversity:  0.839\n",
      "\n",
      "=== Retrieval Uncertainty ===\n",
      "  Mean posterior std:  0.1000\n",
      "  Mean entropy:        0.4150\n"
     ]
    }
   ],
   "source": [
    "print('=== Generation Uncertainty ===')\n",
    "unc = result['uncertainty']\n",
    "print(f'  Sequence entropy:    {unc[\"sequence_entropy\"]:.4f}')\n",
    "print(f'  Mean MI (epistemic): {unc[\"mean_mi\"]:.4f}')\n",
    "print(f'  Unique ratio:        {unc[\"unique_ratio\"]:.2f}')\n",
    "print(f'  Pairwise diversity:  {unc[\"pairwise_diversity\"]:.3f}')\n",
    "print()\n",
    "print('=== Retrieval Uncertainty ===')\n",
    "ret = result['retrieval_uncertainty']\n",
    "print(f'  Mean posterior std:  {ret[\"mean_posterior_std\"]:.4f}')\n",
    "print(f'  Mean entropy:        {ret[\"mean_entropy\"]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a5b6c7",
   "metadata": {},
   "source": [
    "## 4. Interpretation\n",
    "\n",
    "**What do these numbers mean?**\n",
    "\n",
    "| Metric | Measures | High value means |\n",
    "|--------|----------|------------------|\n",
    "| Sequence entropy | Total uncertainty | Model is unsure overall |\n",
    "| Mean MI | Epistemic (model) uncertainty | More data/training could help |\n",
    "| Unique ratio | Sample diversity | Model produces varied answers |\n",
    "| Pairwise diversity | Lexical variation | Answers differ in wording |\n",
    "| Retrieval posterior std | Retrieval confidence spread | Retrieved docs may not be relevant |\n",
    "| Retrieval entropy | Retrieval uncertainty | High = uncertain about doc relevance |\n",
    "\n",
    "**Epistemic uncertainty (MI)** is the part we can reduce with better data or a bigger model.  \n",
    "**Aleatoric uncertainty (expected entropy)** is irreducible noise — even a perfect model would be uncertain.\n",
    "\n",
    "In a production system, you'd flag answers where MI is high as \"the model isn't confident — consider human review.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "22796309e4f64c1683fa06d993eb9b16": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "29a2a7e5247c4c128d10922e44dd6d8a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5c552cdbfb7d466996720e0f183a4bf1",
       "max": 76.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2d08a5c8a00b49e3bb822d47f1db57f5",
       "tabbable": null,
       "tooltip": null,
       "value": 76.0
      }
     },
     "2d08a5c8a00b49e3bb822d47f1db57f5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "44ce64bffe664cb99e3ddb30adaec30b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c3c56ace3f1a44cbad2135d2a216c955",
        "IPY_MODEL_29a2a7e5247c4c128d10922e44dd6d8a",
        "IPY_MODEL_6f5ece1095a84e228e6359d1f80d3fb5"
       ],
       "layout": "IPY_MODEL_ca8168093d2342e0a7504297c3369114",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4a497c8876a845d39195e6668b64f38a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5c552cdbfb7d466996720e0f183a4bf1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6d83eb4828c64b54941df0cb88afb128": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6f5ece1095a84e228e6359d1f80d3fb5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6d83eb4828c64b54941df0cb88afb128",
       "placeholder": "​",
       "style": "IPY_MODEL_f8ea0e731c864a30ac1a46e5a1482ad7",
       "tabbable": null,
       "tooltip": null,
       "value": " 76/76 [00:00&lt;00:00, 2800.90it/s, Materializing param=transformer.wte.weight]"
      }
     },
     "c3c56ace3f1a44cbad2135d2a216c955": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4a497c8876a845d39195e6668b64f38a",
       "placeholder": "​",
       "style": "IPY_MODEL_22796309e4f64c1683fa06d993eb9b16",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading weights: 100%"
      }
     },
     "ca8168093d2342e0a7504297c3369114": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f8ea0e731c864a30ac1a46e5a1482ad7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
